{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simple agents with tools for back-office automation.\n",
        "\n",
        "This notebook introduces you to TogetherAI's inference API for running opensource models.\n",
        "\n",
        "YouTube walkthrough here: []()\n",
        "\n",
        "Connect with the author: [LinkedIn](https://linkedin.com/in/davidimprovz) | [Twitter](https://twitter.com/d_comfe) | [Newsletter](https://drifft.beehiiv.com)"
      ],
      "metadata": {
        "id": "2jHE3VdyvYrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "mkU2hJ4pco_k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZ__IajtYnIt"
      },
      "outputs": [],
      "source": [
        "!pip install langchain # langchain.com\n",
        "!pip install langchain-together # together.ai\n",
        "!pip install duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pprint import pprint\n",
        "from getpass import getpass\n",
        "from langchain_together import Together"
      ],
      "metadata": {
        "id": "5cMQJy3IIu4R"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['TOGETHER_API_KEY'] = getpass()"
      ],
      "metadata": {
        "id": "tZSYKHfklE9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's See Some Models"
      ],
      "metadata": {
        "id": "9sAINq86QTvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test model to make sure it works\n",
        "llama = Together( # default opensource\n",
        "    model=\"togethercomputer/llama-2-70b-chat\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=512,\n",
        "    top_p = 0.7,\n",
        "    top_k=1,\n",
        "    repetition_penalty=1.2,\n",
        ")\n",
        "\n",
        "# test llm\n",
        "answer = llama.invoke(\n",
        "    \"\"\"\n",
        "    Write a short poem about huggingface.\n",
        "    \"\"\",\n",
        "    stop=[\"[/INST]\", \"</s>\"],\n",
        ")\n",
        "\n",
        "pprint(answer)"
      ],
      "metadata": {
        "id": "iR1H9b41UhRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test model to make sure it works\n",
        "mixtral = Together( # default opensource\n",
        "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=512,\n",
        "    top_p = 0.7,\n",
        "    top_k=1,\n",
        "    repetition_penalty=1.2\n",
        ")\n",
        "\n",
        "# test llm\n",
        "answer = mixtral.invoke(\n",
        "    \"\"\"\n",
        "    Break down the following into a set of tasks to complete:\n",
        "\n",
        "    JOB\n",
        "    Write a new python module for interacting with the\n",
        "    CAM-BUS protocol. The module should allow for serial\n",
        "    port interactions, packet sniffing, and deep learning\n",
        "    using PyTorch to generate synthetic data.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "pprint(answer)"
      ],
      "metadata": {
        "id": "oI6BTEizURhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_llama = Together( # write code\n",
        "    model=\"codellama/CodeLlama-70b-Instruct-hf\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=256,\n",
        "    top_k=1,\n",
        "    top_p=0.7,\n",
        "    repetition_penalty=1.2,\n",
        "    )\n",
        "\n",
        "answer = code_llama.invoke(\n",
        "    \"\"\"\n",
        "    Write the code for a serpapi\n",
        "    search of google patents for the term\n",
        "    telepathy.\n",
        "    \"\"\",\n",
        "    stop=['<step>']\n",
        ")\n",
        "\n",
        "pprint(answer)"
      ],
      "metadata": {
        "id": "30zuG8p0TlVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start an agent to use the tools.\n",
        "\n"
      ],
      "metadata": {
        "id": "xYvlqSVLmnm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, initialize_agent\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search = DuckDuckGoSearchRun()\n",
        "chat_history = ConversationBufferWindowMemory(k=2)"
      ],
      "metadata": {
        "id": "Ysvvn3hLsoLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    tools=[search],\n",
        "    llm=mixtral,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    max_retries=3,\n",
        "    memory=chat_history,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "z3aPer2yntsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check out the different types of agents\n",
        "\n",
        "from inspect import getsource\n",
        "\n",
        "pprint(\n",
        "    getsource(AgentType)\n",
        ")"
      ],
      "metadata": {
        "id": "a9NgG3VrykzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_task = \"\"\"\n",
        "Search the web for `mixtral 8x7b model` and `chatgpt`.\n",
        "Then tell me what are the advantages and disadvantages\n",
        "of each model, and suggest which would be better for\n",
        "governing task-based AI agents.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "snSHBbenmtp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke(agent_task)"
      ],
      "metadata": {
        "id": "mTMQWDJ7ecHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Review\n",
        "\n",
        "Together is a great resource for fast inference on opensource models. It's always good practice to have a fallback service other than OpenAI so that you can be sure your chains and agents will run.\n",
        "\n",
        "Contact me if you're looking for specific solutions and want to learn more about how you can integrate these concepts into your workflows. [LinkedIn](https://linkedin.com/in/davidimprovz) | [Twitter](https://twitter.com/d_comfe) | [Newsletter](https://drifft.beehiiv.com)"
      ],
      "metadata": {
        "id": "-lJMzAKEmZun"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xYvlqSVLmnm_"
      ],
      "authorship_tag": "ABX9TyPVcgifafej39fzNcanpWTa"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}