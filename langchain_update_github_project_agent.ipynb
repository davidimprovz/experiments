{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Code Assistant\n",
        "Use an AI to write your code for you for free. \n",
        "Then have it upload it to github. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFnQJ8ZTuzPI"
      },
      "source": [
        "## Environ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Yd5U3nI2unVd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from getpass import getpass\n",
        "import warnings\n",
        "import datetime\n",
        "import os\n",
        "from time import time\n",
        "from pprint import pprint\n",
        "from tqdm import tqdm\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7Qcak_3u3Lu"
      },
      "source": [
        "## Langchain\n",
        "This is the framework that will tie together whatever LLM you choose and your github account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsZYMi5auyAh",
        "outputId": "4de175fd-0848-44b2-f127-94f8edbf5b57"
      },
      "outputs": [],
      "source": [
        "# if you use openai, make sure you get your api token\n",
        "os.environ['OPENAI_API_KEY'] = getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fpvM8bQUuCSn"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import AgentType, initialize_agent\n",
        "from langchain.agents.agent_toolkits.github.toolkit import GitHubToolkit\n",
        "from langchain.utilities.github import GitHubAPIWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load in your github account info securely \n",
        "os.environ[\"GITHUB_APP_ID\"] = getpass()\n",
        "os.environ[\"GITHUB_APP_PRIVATE_KEY\"] = getpass()\n",
        "os.environ[\"GITHUB_REPOSITORY\"] = getpass()\n",
        "os.environ[\"GITHUB_BASE_BRANCH\"] = 'main' # default: \"main\"\n",
        "os.environ[\"GITHUB_BRANCH\"] = 'botify'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rTMluF7St4iK"
      },
      "outputs": [],
      "source": [
        "# set up github \n",
        "\n",
        "github = GitHubAPIWrapper()\n",
        "toolkit = GitHubToolkit.from_github_api_wrapper(github)\n",
        "tools = []\n",
        "unwanted_tools = [\"Get Issue\", \"Delete File\", \"Create File\", \"Create Pull Request\"]\n",
        "for tool in toolkit.get_tools():\n",
        "    if tool.name not in unwanted_tools:\n",
        "        tools.append(tool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "P1rYxOnq6lgs"
      },
      "outputs": [],
      "source": [
        "# create an llm and an AI agent that will use a set of tools to interact with github\n",
        "\n",
        "openai_llm = ChatOpenAI(temperature=0.1, model='gpt-4')\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=openai_llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    max_retries=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "YeDYdESDxKWy"
      },
      "outputs": [],
      "source": [
        "# example prompt telling the llm what you want it to do\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"\"\"\n",
        "You have the software engineering capabilities\n",
        " of a Google Principle engineer. You are tasked with\n",
        " contributing to a code base. Complete the tasks given \n",
        " to you to the best of your ability. Remember to first \n",
        " make a plan and pay attention to details like file \n",
        " names and commonsense. Then execute the plan and use \n",
        " tools appropriately. Finally, if necessary, make a \n",
        " pull request to merge your changes.\n",
        "\n",
        "Issue: {issue}\n",
        "Issue Description: {description}\n",
        "Comments: {comments}\"\"\"\n",
        ")\n",
        "\n",
        "issue = \"get the globals file and read it back to me.\"\n",
        "issue_desc = \"i want to know what the global variables are.\"\n",
        "comments = \"make a bulleted list.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# the chain takes the prompt and passes it to the AI agent to run\n",
        "chain = prompt | agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "k6tiDO3czCZ2"
      },
      "outputs": [],
      "source": [
        "issue = \"get the search.py file and add a new class for Properties. It should be templated similar to the Bikes and RVs classes.\"\n",
        "issue_desc = \"i want to stub in a code template so that I can add more functions later.\"\n",
        "comments = \"add comments to class and function definitions to indicate what they do.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run the agent and see what happens! free software development expertise.\n",
        "# this is only the beginning. \n",
        "\n",
        "output = chain.invoke({\"issue\":issue, \n",
        "           \"description\": issue_desc,\n",
        "           \"comments\": comments,\n",
        "           })\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# idea: add duckduckgo search capabilities to look up api \n",
        "# and other details related to platform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# To Do"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5_aq6Ldu4l1"
      },
      "source": [
        "## Vector DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuFuV3KfzGrL"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import DataFrameLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter # look up others\n",
        "from langchain.embeddings import OpenAIEmbeddings, JinaEmbeddings\n",
        "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain.vectorstores import FAISS, Chroma # or Chroma for in memory, or Pinecone for hosted solution\n",
        "from langchain.document_loaders import TextLoader # look up pandas df\n",
        "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.embeddings import HuggingFaceHubEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "869XUhvtuGe6"
      },
      "outputs": [],
      "source": [
        "# create vectordb\n",
        "# split text\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "\n",
        "# split_docs = text_splitter.split_documents(documents)\n",
        "\n",
        "def make_splits(text):\n",
        "    return text_splitter.split_documents([text])\n",
        "\n",
        "scrape_data['splits'] = scrape_data['document'].apply(make_splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2GAl8G4u6VC"
      },
      "source": [
        "## Github + RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-x19zNNuLbS"
      },
      "outputs": [],
      "source": [
        "# reach in to github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GJ9hNtvuM5h"
      },
      "outputs": [],
      "source": [
        "# generate prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsCepGDBuN6j"
      },
      "outputs": [],
      "source": [
        "# produce code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JDiTIdRvAFy"
      },
      "source": [
        "## QC + Commit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUBxQuFOuPbD"
      },
      "outputs": [],
      "source": [
        "# qc code"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMg26N5jEc39aI/SsmmDndk",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
